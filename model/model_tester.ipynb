{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the necessary libraries - Tested with Python 3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.24.2 torch==2.0.0 anytree transformers==4.27.4 safetensors sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stefanfuchs/Repos/lrml-editor/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "from lrml import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stefanfuchs/Repos/lrml-editor/.conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'sffc348/t5-base-lrml-autocomplete'\n",
    "model = T5ForConditionalGeneration.from_pretrained('sffc348/t5-base-lrml-autocomplete', use_safetensors=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stefanfuchs/Repos/lrml-editor/.conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer_name = 't5-base'\n",
    "\n",
    "def load_tokenizer():\n",
    "    tokenizer = T5Tokenizer.from_pretrained(tokenizer_name)\n",
    "    tokenizer.add_tokens(['<sep>'], special_tokens=True)\n",
    "    tokenizer.sep_token = '<sep>'\n",
    "    tokenizer.sep_token_id = tokenizer.convert_tokens_to_ids(\n",
    "        tokenizer.sep_token)\n",
    "    return tokenizer\n",
    "\n",
    "tokenizer = load_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of text\n",
    "def normalise_text(text):\n",
    "    text = text.strip()\n",
    "    if text and text[-1] != '.':\n",
    "        text += '.'\n",
    "    return text\n",
    "\n",
    "# Generate a prediction based on the input text and the LRML\n",
    "def predict(text, lrml):\n",
    "    num_beams = 5\n",
    "    num_return_sequences = 5\n",
    "    no_repeat_ngram_size = 8\n",
    "    max_length = 256\n",
    "    early_stopping = True\n",
    "    print(text, lrml)\n",
    "    if lrml.strip() != '':\n",
    "        lrml = '<sep>' + lrml\n",
    "    else:\n",
    "        lrml = ''\n",
    "    tokens = tokenizer('translate English to LegalRuleML: ' +\n",
    "                            normalise_text(text) + lrml, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        generation = model.generate(inputs=tokens.input_ids, max_length=max_length, num_beams=num_beams,\n",
    "                                            num_return_sequences=num_return_sequences, early_stopping=early_stopping,\n",
    "                                            no_repeat_ngram_size=no_repeat_ngram_size)\n",
    "\n",
    "    return [post_process(i) for i in tokenizer.batch_decode(generation, skip_special_tokens=True)]\n",
    "\n",
    "# Functions for postprocessing\n",
    "def post_process(lrml):\n",
    "    lrml = lrml.strip()\n",
    "    # lrml = lrml[lrml.find('if('):]\n",
    "    lrml = lrml.replace('[', '(').replace(']', ')').replace(\n",
    "        '{', '(').replace('}', ')')\n",
    "    lrml = lrml.replace(').', ')')\n",
    "    lrml = fix_then(lrml, ' ')\n",
    "    lrml = revert_tree_based_spacing(lrml)\n",
    "    lrml = add_space_after_comma(lrml)\n",
    "\n",
    "    return lrml\n",
    "\n",
    "def clean_pred(lrml):\n",
    "    prefix = ''\n",
    "    lrml = lrml.replace(', ', ',')\n",
    "\n",
    "    lrml = reverse_loop(lrml, prefix=prefix)\n",
    "    lrml = reverse_resolve_expressions(lrml, fix_errors=True, prefix=prefix)\n",
    "    lrml = reverse_combine_rel_and_var(lrml, prefix=prefix)\n",
    "    lrml = reverse_move_and_or_to_data_node(lrml)\n",
    "    lrml = reverse_units(lrml, prefix=prefix)\n",
    "    return lrml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the actual prediction, the LRML input decides the scope of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The floor waste shall have a minimum diameter of 40 mm. if(exist(floorWaste)), then(obligation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['greaterThanEqual(floorWaste.diameter, 40 mm)',\n",
       " 'lessThanEqual(floorWaste.diameter, 40 mm)',\n",
       " 'equal(floorWaste.diameter, 40 mm)',\n",
       " 'exceed(floorWaste.diameter, 40 mm)',\n",
       " 'greaterThanEqual(floorWaste.diameter, 40 mm)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The floor waste shall have a minimum diameter of 40 mm.'\n",
    "# lrml = ''\n",
    "lrml = 'if('\n",
    "lrml = 'if(exist(floorWaste)), then(obligation('\n",
    "predictions = predict(text, lrml)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-process the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'expression(function(greaterThanEqual),atom(relation(diameter),variable(floorWaste)),data(baseunit(prefix(milli),kind(metre)),value(40.0)))'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_pred(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if(expression(function(exist),atom(variable(floorWaste)))),then(obligation)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string = clean_pred(lrml)\n",
    "test_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if(exist(floorWaste)),then(obligation)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lrml_long_to_short import *\n",
    "\n",
    "def get_short_lrml(lrml):\n",
    "    lrml = resolve_units(lrml)\n",
    "    lrml = move_and_or_to_data_node(lrml)\n",
    "    lrml = combine_rel_and_var(lrml)\n",
    "    lrml = resolve_expressions(lrml)\n",
    "    lrml = resolve_loop(lrml)\n",
    "    return lrml\n",
    "\n",
    "get_short_lrml(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  ()\n",
      "Error:  Node('/root/if/expr', node_id=1) (Node('/root/if/expr/atom', node_id=2),) () if(expr(atom))\n",
      "Node('/root/if/expr', node_id=1) (Node('/root/if/expr/atom', node_id=2),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'if(expr(atom))'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lrml_long_to_short import *\n",
    "\n",
    "test_string = 'if(expr(atom('\n",
    "\n",
    "get_short_lrml(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  (Node('/root/if/expr/atom/test', node_id=3),)\n",
      "Error:  Node('/root/if/expr', node_id=1) (Node('/root/if/expr/atom', node_id=2),) () if(expr(atom(test)))\n",
      "Node('/root/if/expr', node_id=1) (Node('/root/if/expr/atom', node_id=2),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'if(expr(atom(test)))'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lrml_long_to_short import *\n",
    "\n",
    "test_string = 'if(expr(atom(test))'\n",
    "\n",
    "get_short_lrml(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  (Node('/root/if/expr/atom/test', node_id=5),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'if(greater(test))'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lrml_long_to_short import *\n",
    "\n",
    "test_string = 'if(expr(fun(greater),atom(test))'\n",
    "\n",
    "get_short_lrml(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
